<!DOCTYPE html>
<html lang="zh-cn">
<head>
  <title>
    
    单目深度估计学习 - 
    Undertaker&#39;s Blog
  </title>
  <meta property="og:title" content="单目深度估计学习 - Undertaker&#39;s Blog" />
  <meta property="og:site_name" content="Undertaker&#39;s Blog" />

  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  

  <meta property="og:type" content="article" />


  
  <link rel="shortcut icon" href="/mylogo.ico" />
  

  

  
  <link rel="canonical" href="https://undertak33r.github.io/2025/10/10/%E5%8D%95%E7%9B%AE%E6%B7%B1%E5%BA%A6%E4%BC%B0%E8%AE%A1%E5%AD%A6%E4%B9%A0/">
  <meta name="og:url" content="https://undertak33r.github.io/2025/10/10/%E5%8D%95%E7%9B%AE%E6%B7%B1%E5%BA%A6%E4%BC%B0%E8%AE%A1%E5%AD%A6%E4%B9%A0/">
  
  <!-- 现代化字体加载 -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap" rel="stylesheet">
  
  <!-- particles.js 库 -->
  <script src="https://cdn.jsdelivr.net/npm/particles.js@2.0.0/particles.min.js"></script>
  
  
<link rel="stylesheet" href="/css/style.css">


<meta name="generator" content="Hexo 8.0.0"></head>

<body>
  

  <div class="title">
  <img class="title_img" alt="Title image" width="300" height="300" src="/images/mylogo.jpg" /><br>
  <div id="site_title">Undertaker's Blog</div>
</div>
  <div class="navi">
  <a id="navi_item_title" href="/#" class="menu-item-link">
    [主页]
  </a>
  <a id="navi_item_tags" href="/tags" class="menu-item-link">
    [标签]
  </a>
  <a id="navi_item_about" href="/about" class="menu-item-link">
    [关于]
  </a>
  <a id="navi_item_search" href="/search" class="menu-item-link">
    [搜索]
  </a>
  
</div>

<hr />

  <div class="main">
    
<link rel="stylesheet" href="/css/post.css">

<post>

  <div class="post_title">
    单目深度估计学习
  </div>

  <br /><br />

  <div id="post_content">
    <p>由于生活不只有自己要学的一些个人技术，还有要完成的学业目标。作为一个苦逼的研究生只能感慨自己本科学习不认真，需要加上研究生生涯让以后好工作时候<br>别人还认得你是个学生。</p>
<p>这篇用来记录我学习我的课题方向的内容，本来想着课题水水就好了，但似乎转别的课题也是一样的起步难，还是算了，就这个课题往下学吧。</p>
<h3 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h3><p>主要需要掌握一下深度学习的流程，这里就不说什么数据集准备，环境搭建啥的，主要聚焦在模型搭建和训练。把模型搭建里面的一些概念记录一下：<br>数据归一化：我们训练的数据的范围不一定固定，有的是0-255有的是别的，为了统一一些我们归一化成0-1或者别的范围，让不同的特征具有相同的量级，便于训练</p>
<p>模型搭建：</p>
<ul>
<li><p>卷积层：原始输入中只有比如RGB三个通道或者灰度图，想要提取出图片中的特征，那么就需要使用卷积层，卷积层中会提取出图片中的特征，比如边缘，纹理等等，卷积核大小一般都是3x3或者5x5。卷积核的数量决定了输出的通道数，比如输入是3通道的图片，卷积核数量为64，那么输出的图片中就会有64个通道，每个通道代表一个特征</p>
</li>
<li><p>池化层：用来降低图片的空间维度，减少计算量和参数数量。例如2×2的最大池化会将128×128的特征图降为64×64</p>
</li>
<li><p>激活函数：卷积层和池化层中都会使用激活函数，比如ReLU，Sigmoid等等，主要是给线形模型提供非线性。</p>
</li>
<li><p>损失函数：训练模型时，需要定义损失函数，比如MSE，MAE等等，主要是用来衡量模型预测结果和真实结果之间的差距，然后根据差距来更新模型参数</p>
</li>
<li><p>优化器：训练模型时，需要定义优化器，比如SGD，Adam等等，主要是用来更新模型参数</p>
</li>
<li><p>正向传播：模型输入图片，经过卷积层和池化层，得到特征图，然后经过全连接层，得到预测结果</p>
</li>
<li><p>反向传播：根据损失函数计算梯度，然后根据梯度更新模型参数</p>
</li>
</ul>
<p>模型参数在哪？<br>我们一般用的pytorch框架搭建自己的模型，框架里面封装参数</p>
<p>注意一下输入数据类型，有的事PIL，有的是tensor，根据函数请求的数据做处理</p>
<h4 id="归一化："><a href="#归一化：" class="headerlink" title="归一化："></a>归一化：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms<br><span class="hljs-comment"># 归一化</span><br><span class="hljs-comment"># 定义均值和标准差</span><br>mean = [<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>]  <span class="hljs-comment"># 对应RGB三个通道的均值</span><br>std = [<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>]  <span class="hljs-comment"># 对应RGB三个通道的标准差</span><br><br><span class="hljs-comment"># 创建transform</span><br>normalize = transforms.Normalize(mean=mean, std=std)<br><br><span class="hljs-comment"># 使用transform</span><br>transform = transforms.Compose([<br>    transforms.ToTensor(),  <span class="hljs-comment"># 将图像转换为Tensor</span><br>    normalize  <span class="hljs-comment"># 对图像进行标准化处理</span><br>])<br><br><span class="hljs-comment"># 应用transform</span><br>normalized_image = transform(image)<br></code></pre></td></tr></table></figure>
<p>公式：input[channel] &#x3D; (input[channel] - mean[channel])&#x2F;std[channel]</p>
<h4 id="模型搭建"><a href="#模型搭建" class="headerlink" title="模型搭建"></a>模型搭建</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyModel, <span class="hljs-variable language_">self</span>).__init__()<br>        <br>        <span class="hljs-comment"># 方法1：逐层定义（推荐用于复杂连接）</span><br>        <span class="hljs-variable language_">self</span>.conv1 = nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)<br>        <span class="hljs-variable language_">self</span>.relu1 = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br>        <span class="hljs-variable language_">self</span>.pool1 = nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>)<br>        <br>        <span class="hljs-comment"># 方法2：使用Sequential（适合简单堆叠）</span><br>        <span class="hljs-variable language_">self</span>.features = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>),<br>            <span class="hljs-comment"># 可以继续添加更多层...</span><br>        )<br>        <br>        <span class="hljs-comment"># 添加分类层（如果需要分类）</span><br>        <span class="hljs-variable language_">self</span>.classifier = nn.Linear(<span class="hljs-number">128</span>, <span class="hljs-number">10</span>)  <span class="hljs-comment"># 示例</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># 使用逐层定义的部分</span><br>        x = <span class="hljs-variable language_">self</span>.conv1(x)<br>        x = <span class="hljs-variable language_">self</span>.relu1(x)<br>        x = <span class="hljs-variable language_">self</span>.pool1(x)<br>        <br>        <span class="hljs-comment"># 使用Sequential部分</span><br>        x = <span class="hljs-variable language_">self</span>.features(x)<br>        <br>        <span class="hljs-comment"># 如果有全连接层，需要展平</span><br>        <span class="hljs-comment"># x = x.view(x.size(0), -1)</span><br>        <span class="hljs-comment"># x = self.classifier(x)</span><br>        <br>        <span class="hljs-keyword">return</span> x<br><br></code></pre></td></tr></table></figure>
<h4 id="损失函数和反向传播"><a href="#损失函数和反向传播" class="headerlink" title="损失函数和反向传播"></a>损失函数和反向传播</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">loss = nn.CrossEntropyLoss() <span class="hljs-comment">#损失函数</span><br>md = MyModel()<br>optim = torch.optim.SGD(md.parameters(),lr=<span class="hljs-number">0.01</span>)<br><span class="hljs-comment"># lr是学习速率</span><br><span class="hljs-keyword">for</span> epoh <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>):<br>    running_loss = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:<br>        imgs, targets = data<br>        outputs = md(imgs)<br>        result_loss = loss(outputs, targets)<br>        optim.zero_grad()  <span class="hljs-comment"># 将梯度清零</span><br>        result_loss.backward()  <span class="hljs-comment"># 通过反向传播求出每一个节点的梯度</span><br>        optim.step()  <span class="hljs-comment"># 对每一个进行调优</span><br>        <span class="hljs-comment"># print(result_loss)</span><br>        running_loss = running_loss + result_loss<br>    <span class="hljs-built_in">print</span>(running_loss)<br><br></code></pre></td></tr></table></figure>

<h3 id="单目深度估计"><a href="#单目深度估计" class="headerlink" title="单目深度估计"></a>单目深度估计</h3><p>单目深度估计指的是输入一张图片，输出一张深度图，深度图表示的是图片中各个像素点的深度。<br>单目深度估计是一个病态问题，因为把一个3维的空间变成二维图像本身就丢失第三维度的深度信息，从2D投影恢复3D结构存在本质上的信息缺失。<br>同时，即使知道物体的相对深度关系，也无法确定绝对尺度。<br>而且，同一张2D图像可能对应多种不同的3D场景结构，没有唯一解。</p>
<p>此外，单目深度估计的数据集成本较高，本身没有丰富的绝对尺度数据集的同时，不同数据集之间的尺度单位不同。<br>种种条件上看来，单目深度估计存在很大挑战。</p>
<p>现在我了解到的一些当下的效果较好的单目深度估计的模型有：depth anything2，Marigold等。<br>这两种模型代表了不同的两类单目深度估计模型的思路：判别式模型和生成式模型。</p>
<h4 id="判别式模型"><a href="#判别式模型" class="headerlink" title="判别式模型"></a>判别式模型</h4><p>核心目标是直接学习从输入图像到深度图的映射关系，通过最小化预测深度与真实深度（Ground Truth）的回归损失（如 MSE、AbsRel 等），输出逐像素的深度值。<br>常用神经网络实现端到端映射。</p>
<h4 id="生成式模型"><a href="#生成式模型" class="headerlink" title="生成式模型"></a>生成式模型</h4><p>生成式模型是单目深度估计领域的新兴技术路径，其核心目标是学习深度值的逐像素概率分布，而非直接输出确定性深度映射。<br>当下的新兴模型主要是用扩散模型学习深度值的分布规律，可生成多个符合场景逻辑的深度预测结果。</p>
<p>接下来结合论文来讲解下两个模型</p>
<h4 id="Depth-Anything"><a href="#Depth-Anything" class="headerlink" title="Depth Anything"></a>Depth Anything</h4><p>Depth Anything系列的工作是在MiDas的基础上进行对自监督训练和样本扩大的尝试。<br>而MiDas的主要贡献在于强调数据量的作用和提出了偏移和尺度不变损失来整合过去的一些数据集，提高模型的泛化能力。<br>在Depth Anything V1中，研究者复现了MiDas，并在此基础上，采用DINO V2预训练权重来初始化编码器，训练教师模型对规模巨大的无标注数据进行伪标签标注。<br>训练出的教师模型对未标注的大规模数据集进行标注，生成伪标签，然后训练学生模型。<br>研究者发现直接用带伪标签的数据集进行训练的学生模型效果不佳。<br>于是他们对已经进行伪标签标注的数据集添加颜色扰动和cutmix进行数据增强，让学生模型学习到更丰富的特征。<br>此外他们结合语意分割进行辅助。在尝试一设计一个共享编码起和两个独立解码器后，对深度估计效果没有显著帮助，由于单纯的解码成离散的语意标签如车而不分清车头车尾，丢失了太多了语意细节。<br>于是研究者使用了DINO V2丰富语意先验知识，在训练中使用特征对齐损失来提升模型性能。让深度模型的编码器和 DINOv2 的编码器“对齐”，同时添加容忍度防止语意模型和深度模型之间的差异过大。<br>Depth Anything V2在Depth Anything V1的基础上进行了进一步研究。在此次研究中进一步提高了数据量，同时，相较于V1，V2更加重视对合成数据的使用。<br>原本的教师模型使用现实数据集中由于设备的固有缺陷导致真实数据集中反而有许多噪音，比如光学测距对透明物体的测距会有偏差，使用合成数据反而能一定程度避免噪声问题。<br>Depth Anything V2的作者对使用合成数据的挑战进行了归纳 ：合成数据的场景有限，同时合成数据的场景过于干净，模型对复杂的现实环境泛化能力有限。<br>研究者的解决办法是使用真实图像来训练学生模型，并使用合成数据来训练教师模型，将两种场景进行桥接 。<br>具体训练中，依旧使用DINO V2作为编码起，根据编码器实现DPT解码器。相对于V1，学生学习的真实数据量扩大到了约62M张。<br>最后，Depth Anything2还针对过去测试数据集本身精度不足的情况推出了DA-2K测试标准，并表现优异。<br>Depth Anything2是非常优秀的判别式模型，与基于 Stable Diffusion 的生成式模型相比，速度快 10 倍以上且准确性更高，提供不同规模模型（25M - 1.3B 参数）支持广泛下游应用场景。</p>
<h4 id="Marigold"><a href="#Marigold" class="headerlink" title="Marigold"></a>Marigold</h4><p>相对于Depth Anything的力大砖飞，针对具体任务从头训练针对性模型，Marigold则开启了一个新的方向，使用当前扩散模型丰富的先验知识，改造文生图模型为图生图模型，并适配单目深度估计任务。<br>首先是对Stable Diffusion模型进行讲解 。<br>Stable Diffusion模型是一个基于扩散模型（Denoising Diffusion Probabilistic Models，DDPM）的文本到图像生成模型。<br>什么是扩散模型呢？<br>以潜在空间扩散模型为例子，先将原始图像用变分自编码器VAE将原始输入编译到低维潜在空间，然后进行加噪，后续通过去噪来复原图像的过程。在去噪过程中需要预测噪声，并间接学习到输入的图像特征。<br>研究者对原始Stable Diffusion模型进行了轻量级的微调，冻结了VAE等组件，仅微调U-net。<br>模型结构如下：<br>首先将原始RGB图像和深度图像分别进行VAE编码，将获得的潜在空间深度信息进行加噪（逐步添加高斯噪声或者退火多分辨噪声），加噪后的潜在空间深度和潜在空间RGB图像进行拼接。<br>对U-Net进行微调，把输入扩展到6通道，并对第一层的权重进行除以二操作防止激活值膨胀。</p>
<p>除了对模型的微调外，Marigold还在真值深度图输入到VAE前进行仿射不变深度归一化，并将通道数扩展到3来适配VAE输入。<br>采用的数据集为vKITTI和Hypersim，他们都是合成数据。<br>研究者仅采用越54K量的数据在4090上训练2.5天就实现了在现实数据集上SOTA的效果，可见其泛化能力之强。</p>
<h4 id="额外内容"><a href="#额外内容" class="headerlink" title="额外内容"></a>额外内容</h4><ul>
<li>Pixel-Perfect Depth<br>单目深度估计模型有许多下游应用场景，其中点云生成就是其中非常常重要的一个场景且点云生成是验证模型性能的核心场景之一。<br>不过当前的模型无论是生成式模型还是判别式模型，在点云生成过程中由于物体边缘的深度值差异较大，在生成点云图像时会产生严重的飞点问题，导致生成的点云图像有严重瑕疵。<br>本篇论文提出的Pixel-Perfect Depth模型，总结了不同模型在生成点云时出现飞点问题的原因，并针对该问题提供了一种有效的解决方案。<br>首先是判别式模型，由于生成的深度图内图像边缘深度差距较大，模型在生成边缘深度信息时会采取折中的策略，导致图像之间出现不规则飞点。<br>而生成式模型由于将图像先用VAE进行降采样，再进行复原，导致一些原始信息丢失，从而导致生成点云图像有飞点。<br>该模型研究者给出的解决办法是基于生成式模型，不进行VAE，直接在像素空间进行扩散。<br>这引出了如下问题： 直接在像素空间进行扩散，收敛困难且模型效果差，同时计算成本高昂。<br>该模型为了解决该问题提出了如下设计：<br>语义提示扩散Transformer（Semantics-Prompted Diffusion Transformers，SP-DiT）<br>级联 DiT 设计（Cascade DiT Design，Cas-DiT）</li>
</ul>
<p>由于直接在像素空间进行扩散，输入图像的数值太多，模型很难在保证全局语意一致性（就是桌子得立在地上等）的情况下保证细粒度视觉细节。<br>语义提示扩散Transformer（SP-DiT）使用例如DINO V2等视觉基础模型来快速识别高层语意，利用提取的语意保证全局语意一致性。<br>通过 “双线性插值” 对齐语义与DiT tokens 的空间分辨率，再通过 MLP 融合，最终实现 “全局语义一致性” 与 “细粒度细节” 的平衡。<br>提取的语意token和DiT本身的token数值差异较大，所以要进行L2归一化。<br>级联DiT设计（Cas-DiT）则是因为直接在像素空间进行扩散训练数据巨大，在训练过程中对patch的大小进行调整，开始训练使用大patch，训练到后面用小patch。<br>从粗到细的级联设计不仅显著降低了计算成本提高了效率，而且还带来了显著的准确性增益。</p>

  </div>

  <br />

  
  <br /><br />


  

<div id="copyright">

  <a id="license-image" rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img height="15" width="80" alt="知识共享 署名-非商业性使用-相同方式共享 4.0 国际许可协议" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" />
  </a>

  <p id="license-word-hyper">
    本作品采用
    <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">
    知识共享 署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>
    进行许可。
  </p>
</div>

  <div id="top">
  <div onclick="window.scrollTo({top: 0, behavior: 'smooth'})">▲</div>
  <div onclick="document.getElementById('footer').scrollIntoView({behavior: 'smooth'})">▼</div>
</div>
  

</post>
  </div>

  <foot id="footer">
  <hr class="boldline" />
  <br>

  <p class="center font">
    
    <a target="_blank" rel="noopener" href="https://github.com/UndertaK33r" aria-label="GitHub">
  <svg class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
   <path class="icon_path" d="M427.392 853.504a61.44 61.44 0 0 1-1.450667 15.530667 92.586667 92.586667 0 0 1-10.965333 27.605333c-15.061333 25.301333-40.661333 42.154667-73.642667 42.154667-77.653333 0-108.117333-38.101333-146.261333-133.504C169.216 740.693333 157.013333 725.461333 128 725.461333v-85.333333c77.653333 0 108.117333 38.101333 146.261333 133.504 25.856 64.597333 38.058667 79.786667 67.072 79.786667 0-12.373333-0.170667-23.296-0.512-38.144-0.853333-34.816-0.938667-41.941333 0.554667-51.2 0.64-20.352 5.888-34.773333 16.384-49.066667-95.232-20.736-159.445333-63.573333-196.309333-132.992l-13.824-32.426667C134.186667 510.848 128 467.072 128 416.426667c0-58.24 17.749333-110.336 50.944-153.856-10.368-41.386667-8.96-91.989333 13.909333-149.077334l7.466667-18.688 19.2-6.101333c2.56-0.853333 5.632-1.578667 9.301333-2.133333 37.290667-5.888 90.325333 8.106667 159.701334 52.48a565.930667 565.930667 0 0 1 127.274666-14.208c38.741333 0 77.226667 3.882667 114.048 11.605333 67.456-42.24 119.04-55.509333 155.306667-49.92 3.626667 0.597333 6.741333 1.322667 9.258667 2.133333l19.285333 6.101334 7.466667 18.773333c20.010667 50.218667 23.424 96.469333 16.128 136.96C875.434667 296.32 896 352.597333 896 416.512c0 53.888-3.84 94.378667-14.933333 133.802667l-11.733334 32.170666c-30.677333 69.333333-98.304 112.64-202.538666 133.248 10.837333 15.018667 15.872 30.250667 15.872 52.394667v42.666667l-0.042667 42.666666a13.013333 13.013333 0 0 0 0.341333 2.730667L682.666667 938.794667c-36.352 0-63.36-17.706667-76.672-45.653334a88.277333 88.277333 0 0 1-8.661334-40.277333v-84.736c0-3.584-0.128-3.797333-8.832-12.501333-23.296-23.296-33.834667-40.874667-33.834666-72.832v-38.613334l38.4-3.84c114.346667-11.52 176.512-43.221333 197.12-89.6l9.6-26.325333c7.68-27.562667 10.88-61.098667 10.88-107.946667 0-49.706667-17.365333-90.837333-50.218667-123.648L742.4 274.773333l7.381333-24.448c6.528-21.717333 8.106667-47.402667 1.152-76.714666a158.634667 158.634667 0 0 0-3.584 0.938666c-22.826667 6.4-51.370667 20.053333-85.76 43.008l-15.658666 10.453334-18.304-4.522667a467.754667 467.754667 0 0 0-111.829334-13.269333c-42.709333 0-84.906667 5.418667-123.946666 16.042666l-19.029334 5.205334-16.256-11.136c-35.541333-24.32-65.109333-38.826667-88.746666-45.568a158.293333 158.293333 0 0 0-4.864-1.28c-8.234667 33.92-4.992 61.781333 3.413333 82.688l9.984 25.088-18.346667 19.797333C228.693333 332.629333 213.333333 370.986667 213.333333 416.512c0 41.685333 4.864 76.202667 13.824 102.229333l11.178667 26.453334c27.904 52.352 87.168 83.84 192.853333 95.146666l38.144 4.096v38.357334c0 32-10.538667 49.536-33.834666 72.832-8.704 8.704-8.832 8.96-8.832 12.501333l-0.725334 7.893333c-0.512 2.56-0.512 9.258667 0.170667 37.205334 0.298667 12.8 0.469333 22.997333 0.554667 33.621333a33.962667 33.962667 0 0 1 0.725333 6.656z"/>
  </svg>
 </a>

    
    
    <a href="mailto:2331627921@qq.com" aria-label="Email">
  <svg class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
    <path d="M513.78 602.99c-27.28 0.45-53.79-9.09-74.53-26.83l-65.96-56.64c-15.64-13.37-17.48-36.9-4.1-52.54 13.38-15.65 36.9-17.48 52.54-4.1l65.96 56.64c13.68 11.1 33.27 11.1 46.95 0L881.2 253.08l-708.02-2.61c-20.58 0-37.26-16.69-37.26-37.26s16.68-37.26 37.26-37.26H881.2c41.09-2.36 76.32 29.05 78.67 70.14a74.519 74.519 0 0 1-32.46 65.87L580.86 578.38a111.842 111.842 0 0 1-67.08 24.61z m444.57 133.4V438.28c0-20.58-16.68-37.26-37.26-37.26s-37.26 16.69-37.26 37.26V736.4c0 20.58-16.68 37.26-37.26 37.26h-521.7c-20.58 0-37.26 16.69-37.26 37.26s16.68 37.26 37.26 37.26h521.7c61.72 0.01 111.78-50.05 111.78-111.79zM362.12 363.75c0-20.58-16.68-37.26-37.26-37.26h-223.6c-20.58 0-37.26 16.69-37.26 37.26s16.68 37.26 37.26 37.26h223.59c20.58 0.01 37.27-16.68 37.27-37.26z m0 298.12c0-20.58-16.68-37.26-37.26-37.26h-111.8c-20.58 0-37.26 16.69-37.26 37.26s16.68 37.26 37.26 37.26h111.79c20.58 0 37.27-16.69 37.27-37.26z"/>
  </svg>
</a>

    
    
    
    
    
    
    
    
    
  <p>
    <br>
  <p id="hitokoto">:D 获取中...</p>
  <script src="https://v1.hitokoto.cn/?c=a&encode=js&select=%23hitokoto" defer></script>
  <br>
  <p class="center font">
    &copy - <a href="https://UndertaK33r.github.io">UndertaK33r</a> -  2025 - Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>  Theme <a target="_blank" rel="noopener" href="https://github.com/pcrab/hexo-theme-quark"> Quark </a> 
  </p>
  
  <br />
</foot>
  
  
  
<script src="/js/perf-toggle.js"></script>

</body>

</html>